# Topic-Modelling-using-Machine-Learning-LDA-

In [1]: All the necessary imports are called.

In [2]: This is the main Pre-processing part where the data is tokenised and all the punctuations, digits, stopwords are removed and further stemming is done using the snowball stemmer algorithm.

In[3]: Data is extracted using Pandas framework.

In[4]: Count vectorization is done inorder to get a Bag-of-words representation of the data that is extracted.

In[5]&[6]: This is the learning part where the no. of topics chosen are 2 for optimality.

In[7]&[8]: Shows the trend analysis visually.

In[9] - In[14]: Here coherence score of the trained model is calculated and it is optimised by Brute force to get the most optimal values for alpha, beta and the no. of topics.
